{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from tensorflow.keras.utils import load_img\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Conv2D, Dense, BatchNormalization, Activation, Dropout, MaxPooling2D, Flatten\n",
    "from keras.optimizers import Adam, RMSprop, SGD\n",
    "from keras import regularizers\n",
    "from keras.callbacks import ModelCheckpoint, CSVLogger, TensorBoard, EarlyStopping, ReduceLROnPlateau\n",
    "import datetime\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = '/Users/vutrang/Documents/VMD/archive/train/'\n",
    "test_dir = '/Users/vutrang/Documents/VMD/archive/test/'\n",
    "\n",
    "row, col = 48, 48\n",
    "classes = 7\n",
    "\n",
    "def count_exp(path, set_):\n",
    "    dict_ = {}\n",
    "    for expression in os.listdir(path):\n",
    "        dir_ = path + expression\n",
    "        dict_[expression] = len(os.listdir(dir_))\n",
    "    df = pd.DataFrame(dict_, index=[set_])\n",
    "    return df\n",
    "train_count = count_exp(train_dir, 'train')\n",
    "test_count = count_exp(test_dir, 'test')\n",
    "print(train_count)\n",
    "print(test_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                   zoom_range=0.3,\n",
    "                                   horizontal_flip=True)\n",
    "train_set = train_datagen.flow_from_directory(train_dir,\n",
    "                                              batch_size=64,\n",
    "                                              target_size=(48, 48),\n",
    "                                              shuffle=True,\n",
    "                                              color_mode=\"grayscale\", class_mode='categorical')\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_set = test_datagen.flow_from_directory(test_dir,\n",
    "                                            batch_size=64,\n",
    "                                            target_size=(48, 48),\n",
    "                                            shuffle=True,\n",
    "                                            color_mode=\"grayscale\", class_mode='categorical')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(input_size, classes=7):\n",
    "     #Initialising the CNN\n",
    "    model = tf.keras.models.Sequential()   \n",
    "\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3), padding='same', activation='relu', input_shape =input_size))\n",
    "    model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(2, 2))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same', kernel_regularizer=regularizers.l2(0.01)))\n",
    "    model.add(Conv2D(256, kernel_size=(3, 3), activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Dense(classes, activation='softmax'))\n",
    "\n",
    "    #Compliling the model\n",
    "    model.compile(optimizer=Adam(learning_rate=0.0001, decay=1e-6), \n",
    "                  loss='categorical_crossentropy', \n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "our_model = get_model((row,col,1), classes)\n",
    "our_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_per_epoch = train_set.n // train_set.batch_size\n",
    "validation_steps = test_set.n // test_set.batch_size\n",
    "\n",
    "mod = our_model.fit(x=train_set,\n",
    "                    validation_data=test_set,\n",
    "                    epochs=60,\n",
    "                    steps_per_epoch=steps_per_epoch,\n",
    "                    validation_steps=validation_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 5))\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(mod.history['accuracy'])\n",
    "plt.plot(mod.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(['train', 'test'], loc='upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss, train_accu = our_model.evaluate(train_set)\n",
    "test_loss, test_accu = our_model.evaluate(test_set)\n",
    "print(\"final train accuracy = {:.2f} , validation accuracy = {:.2f}\".format(train_accu*100, test_accu*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ON TRAINING SET\n",
    "y_pred = our_model.predict(train_set)\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "class_labels = test_set.class_indices\n",
    "class_labels = {v: k for k, v in class_labels.items()}\n",
    "\n",
    "cm_train = confusion_matrix(train_set.classes, y_pred)\n",
    "print('Confusion Matrix')\n",
    "print(cm_train)\n",
    "print('Classification Report')\n",
    "target_names = list(class_labels.values())\n",
    "print(classification_report(train_set.classes, y_pred, target_names=target_names))\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.imshow(cm_train, interpolation='nearest')\n",
    "plt.colorbar()\n",
    "tick_mark = np.arange(len(target_names))\n",
    "_ = plt.xticks(tick_mark, target_names, rotation=90)\n",
    "_ = plt.yticks(tick_mark, target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ON TESTING SET\n",
    "y_pred = our_model.predict(test_set)\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "class_labels = test_set.class_indices\n",
    "class_labels = {v: k for k, v in class_labels.items()}\n",
    "\n",
    "#from sklearn.metrics import classification_report, confusion_matrix\n",
    "cm_test = confusion_matrix(test_set.classes, y_pred)\n",
    "print('Confusion Matrix')\n",
    "print(cm_test)\n",
    "print('Classification Report')\n",
    "target_names = list(class_labels.values())\n",
    "print(classification_report(test_set.classes, y_pred, target_names=target_names))\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.imshow(cm_test, interpolation='nearest')\n",
    "plt.colorbar()\n",
    "tick_mark = np.arange(len(target_names))\n",
    "_ = plt.xticks(tick_mark, target_names, rotation=90)\n",
    "_ = plt.yticks(tick_mark, target_names)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
